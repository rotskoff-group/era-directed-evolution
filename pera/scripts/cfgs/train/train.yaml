lightning_model: "BidirectionalModel"
resume_training_path: null
lightning_model_args:
  eval_type: "era"
  beta: -10.0
  gamma: 0.01
  sampling_temperature: 1.0
  # optimizer: "AdamW"
  # optimizer_args:
  #   lr: 4.0E-4
  #   betas: [0.9, 0.95]
  #   weight_decay: 0.01
  optimizer: "RMSprop"
  optimizer_args:
    lr: 1E-5
  lr_scheduler: "LinearWarmupCosineAnnealingLR"
    #lr_scheduler_args:
    #warmup_epochs: 25000
    #max_epochs: 2500000
    #eta_min: 1E-7
  interval: "step"
  monitor: "val/ERALoss"
  sync_dist: True
  on_step: True
trainer_args: 
  accelerator: "cuda"
  devices: 2
  precision: "16-mixed"
  log_every_n_steps: 100
  max_epochs: 10000
  enable_progress_bar: False
  gradient_clip_val: 1.0
  # logger: "TensorBoardLogger"
strategy: DDPStrategy
strategy_args: 
  find_unused_parameters: True #"SHARD_GRAD_OP" #FULL_SHARD
every_epoch_checkpoint_args:
  filename: "epoch_{epoch:02d}"
  every_n_epochs: 10
  every_n_train_steps: null
  save_top_k: -1
best_checkpoint_args:
  filename: "best_model"
  monitor: "validation/loss"
  mode: "min"
  save_top_k: 1
logger:
  loggertype: "TensorBoard"
  logger_args:
    version: null
seed_args:
  seed: 42
  workers: True
